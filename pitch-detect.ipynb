{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, sys\n",
    "import pickle, csv\n",
    "import time\n",
    "import datetime\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import plotly.express as px\n",
    "\n",
    "import librosa\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from IPython.display import Audio as ipy_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quicktranscribe import tonic, pitch, wave, kde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/neerajaabhyankar/Repos/icm-shruti-analysis/data-dunya-hindustani/\"\n",
    "track = \"Omkar Dadarkar - Raag Bhoopali\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metadata, Tonic, Pitch, Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata = tonic.read_metadata(data_dir + track + \".json\")\n",
    "ctonic = tonic.read_tonic(data_dir + track + \".ctonic.txt\")\n",
    "pitch_annotations, aps = pitch.read_pitch(data_dir + track + \".pitch.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y, sr = wave.get_audio(data_dir + track + \".mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a representative sample\n",
    "start=9*60+45\n",
    "end=10*60\n",
    "y_stereo, sr = wave.read_audio_section(data_dir + track + \".mp3\", start, end)\n",
    "y_sample = librosa.to_mono(y_stereo.T)\n",
    "ipy_audio(data=y_sample, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from below repurposed into a single function\n",
    "kde_sample = kde.extract(y_sample, sr=sr, tonic=ctonic)\n",
    "\n",
    "plt.plot(np.linspace(0, 12, len(kde_sample)), kde_sample, color=\"green\")\n",
    "plt.xlabel(\"relative note index\")\n",
    "plt.ylabel(\"normalized duration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librosa Pitch Detection with `pyin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "fpd_bin_width = 0.05  # of a midi note\n",
    "frame_length = 2048\n",
    "frame_hop_length = frame_length // 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pitch tracking\n",
    "f0, voiced_flag, voiced_probs = librosa.pyin(\n",
    "    y_sample,\n",
    "    fmin=ctonic/2, fmax=ctonic*4,\n",
    "    frame_length=frame_length\n",
    ")\n",
    "\n",
    "# convert frequency to MIDI for easier binning\n",
    "# needed since midi is in log scale already\n",
    "f0_midi = librosa.hz_to_midi(f0)\n",
    "\n",
    "# subtract tonic + fold into octave\n",
    "f0_relative = (f0_midi-librosa.hz_to_midi(ctonic)) % 12\n",
    "f0_relative = f0_relative[~np.isnan(f0_relative)]\n",
    "\n",
    "# get a duration-binned histogram\n",
    "fpd_bins = np.arange(0, 12.0001, fpd_bin_width)\n",
    "pitch_distribution, _ = np.histogram(f0_relative, bins=fpd_bins)\n",
    "time_per_frame = librosa.frames_to_time(1, sr=sr, hop_length=frame_hop_length)\n",
    "duration_per_bin = pitch_distribution * time_per_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(fpd_bins[:-1], duration_per_bin, width=fpd_bin_width)\n",
    "plt.xlabel(\"relative note index (5-cent granularity)\")\n",
    "plt.ylabel(\"duration (s)\")\n",
    "plt.title(\"Finegrained Pitch Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Smoothed PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_granularity = 240\n",
    "kde_bandwidth = 0.1\n",
    "supp = np.linspace(0, 12, kde_granularity).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "kde = KernelDensity(kernel=\"gaussian\", bandwidth=kde_bandwidth).fit(f0_relative.reshape(-1, 1))\n",
    "logkde = kde.score_samples(supp)\n",
    "kde_sample = np.exp(logkde)\n",
    "plt.plot(supp, duration_per_bin, alpha=0.5)\n",
    "plt.plot(supp, kde_sample, color=\"green\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # alternatively\n",
    "# from scipy import stats\n",
    "# kde = stats.gaussian_kde(f0_relative, bw_method=0.01)\n",
    "# x = np.linspace(0, 12, kde_granularity)\n",
    "# p = kde(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librosa Pitch Detection with `piptrack`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_pitch(y, sr):\n",
    "    pitches, magnitudes = librosa.core.piptrack(y=y, sr=sr, fmin=110, fmax=320)\n",
    "    # get indexes of the maximum value in each time slice\n",
    "    max_indexes = np.argmax(magnitudes, axis=0)\n",
    "    # get the pitches of the max indexes per time slice\n",
    "    pitches = pitches[max_indexes, range(magnitudes.shape[1])]\n",
    "    return pitches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sample = detect_pitch(y_sample, sr)\n",
    "ar = len(p_sample)/(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(p_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_sample = np.array(p_sample/ctonic)\n",
    "nz_annotations = np_sample[np.where(np_sample[:] != 0)]\n",
    "h = np.histogram(nz_annotations, bins=700)\n",
    "counts = h[0]\n",
    "fro = (h[1][:-1] + h[1][1:]) / 2\n",
    "\n",
    "plt.figure()\n",
    "fig = px.line(\n",
    "    pd.DataFrame({\"fratio\": fro, \"count\": counts}),\n",
    "    x=\"fratio\",\n",
    "    y=\"count\",\n",
    "    log_x=True,\n",
    "    width=600,\n",
    "    height=200,\n",
    ")\n",
    "fig.update_xaxes(range=[np.log10(0.6), np.log10(2.6)], type=\"log\")\n",
    "fig.update_xaxes(minor=dict(showgrid=True, nticks=10))\n",
    "fig.update_traces(\n",
    "    hovertemplate=\"frequency(ratio wrt root): %{x}<br>occurence: %{y}\"\n",
    ")\n",
    "fig.update_layout(\n",
    "    margin=dict(l=10, r=20, t=30, b=10),\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a waveform\n",
    "y_from_p_sample = []\n",
    "for anno in p_sample:\n",
    "    tone = librosa.tone(\n",
    "        2 * anno, sr=sr, length=sr / ar\n",
    "    )\n",
    "    y_from_p_sample += tone.tolist()\n",
    "\n",
    "ipy_audio(data=y_from_p_sample, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pitch Detection Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_pitch(y, sr):\n",
    "    pitches, magnitudes = librosa.core.piptrack(y=y, sr=sr, fmin=110, fmax=440)\n",
    "    # get indexes of the maximum value in each time slice\n",
    "    max_indexes = np.argmax(magnitudes, axis=0)\n",
    "    # get the pitches of the max indexes per time slice\n",
    "    pitches = pitches[max_indexes, range(magnitudes.shape[1])]\n",
    "    return pitches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTONE = 1  # 1 pitch annotation per second --> 5 second audio\n",
    "SRTONE = 22050\n",
    "\n",
    "def create_tone(f, duration=5):\n",
    "    # create a waveform\n",
    "    pitch_list = [f,]*duration\n",
    "\n",
    "    y_tone = []\n",
    "    for anno in pitch_list:\n",
    "        tone = librosa.tone(\n",
    "            2 * anno, sr=SRTONE, length=SRTONE / ARTONE\n",
    "        )\n",
    "        y_tone += tone.tolist()\n",
    "    \n",
    "    return y_tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_detect(f0):\n",
    "    y_tone = create_tone(f0)\n",
    "    p0 = np.mean(detect_pitch(np.array(y_tone), SRTONE))\n",
    "    return p0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = np.arange(65, 330, 5)\n",
    "ps = [create_and_detect(ff) for ff in fs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(fs, ps, label=\"detected pitch\")\n",
    "plt.plot(fs, fs, linestyle=\":\", label=\"expected pitch\", c=\"limegreen\")\n",
    "plt.plot(fs, 2*fs, linestyle=\":\", label=\"expected pitch\", c=\"limegreen\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fs[:30], ps[:30]-2*fs[:30], linestyle=\":\", label=\"delta (detected - expected) pitch\")\n",
    "plt.ylabel(\"delta (Hz)\")\n",
    "plt.xlabel(\"true pitch (Hz)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icm-shruti-analysis-XL3d-GDY-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
