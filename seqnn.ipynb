{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "import librosa\n",
    "from IPython.display import Audio as ipy_audio\n",
    "from IPython.core.display import display\n",
    "\n",
    "from quicktranscribe import tonic, pitch, wave, kde\n",
    "from mogra import tonnetz\n",
    "from mogra.datatypes import Swar, normalize_frequency, ratio_to_swar, SWAR_BOUNDARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from torch_geometric_temporal.nn.recurrent import GConvGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tonnetz Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the net\n",
    "gs = tonnetz.EFGenus.from_list([3,3,3,3,5,5])\n",
    "tn = tonnetz.Tonnetz(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the adjacency and equivalence matrices\n",
    "adjac = tn.adjacency_matrix()\n",
    "equiv = tn.equivalence_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pitch Tracked Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sample_and_tonic(track_path, start_min=5, end_min=10):\n",
    "    \n",
    "    ctonic = tonic.read_tonic(track_path + \".ctonic.txt\")\n",
    "    y_stereo, sr = wave.read_audio_section(track_path + \".mp3\", int(start_min*60), int(end_min*60))\n",
    "    y_sample = librosa.to_mono(y_stereo.T)\n",
    "    \n",
    "    return y_sample, sr, ctonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(track):\n",
    "    # downsample\n",
    "    track = track[::16]\n",
    "    # drop nans\n",
    "    track = track[~np.isnan(track)]\n",
    "    # round to nearest int\n",
    "    track = np.round(track).astype(int)\n",
    "    \n",
    "    return track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"concrete-demo/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist = \"AjoyChakrabarty\"\n",
    "raags_and_times = {\n",
    "    # \"Bhoop\": [(4,6), (7,9), (10,12), (13,15), (16,18), (19,21)],\n",
    "    # \"Deshkar\": [(4,6), (7,9), (10,12), (13,15), (16,18), (19,21)],\n",
    "    # \"Bhoop\": [(3,21)],\n",
    "    # \"Deshkar\": [(3,21)],\n",
    "    \"Bhoop\": [(3,21)],\n",
    "    \"Deshkar\": [(3,21)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seqs = OrderedDict({rr:[] for rr in raags_and_times.keys()})\n",
    "# for raag in raags_and_times.keys():\n",
    "#     track_mp3 = glob.glob(DATA_DIR + f\"*{raag}*{artist}.mp3\")[0]\n",
    "#     track_path = track_mp3[:-4]\n",
    "#     for start_min, end_min in tqdm(raags_and_times[raag]):\n",
    "#         y_sample, sr, ctonic = read_sample_and_tonic(track_path, start_min, end_min)\n",
    "#         ftrack = pitch.track_pitch_pyin(y_sample, sr, ctonic)\n",
    "#         seqs[raag].append(preprocess(ftrack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"seqs.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(seqs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"seqs.pkl\", \"rb\") as f:\n",
    "    seqs = OrderedDict(pickle.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define + Plot Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raag_gt_ratios = {\n",
    "    \"Bhoop\": [1, 10/9, 5/4, 3/2, 5/3],\n",
    "    \"Deshkar\": [1, 9/8, 81/64, 3/2,  27/16],\n",
    "    \"Yaman\": [1, 9/8, 5/4, 45/32, 3/2, 27/16, 15/8],\n",
    "}\n",
    "raag_gt_nodes = {\n",
    "    \"Bhoop\": [(0,0), (1,0), (0,1), (-1,1), (-2,1)],\n",
    "    \"Deshkar\": [(0,0), (1,0), (2,0), (3,0), (4,0)],\n",
    "    \"Yaman\": [(0,0), (1,0), (2,0), (1,1), (2,1), (0,1), (3,0)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.graph_objects as go\n",
    "# for raag, gt_nodes in raag_gt_nodes.items():\n",
    "#     fig = go.Figure(data=[go.Scatter(\n",
    "#         x=tn.coords3d[0],\n",
    "#         y=tn.coords3d[1],\n",
    "#         mode=\"text+markers\",\n",
    "#         marker=dict(\n",
    "#             size=21,\n",
    "#             symbol=\"circle\",\n",
    "#             color=[\"#e0b724\" if coord in gt_nodes else \"midnightblue\" for coord in tn.node_coordinates]\n",
    "#         ),\n",
    "#         text=tn.node_names,\n",
    "#         textposition=\"middle center\",\n",
    "#         textfont=dict(family=\"Overpass\", size=13, color=\"white\"),\n",
    "#     )])\n",
    "    \n",
    "#     # fig = tn.prep_plot(fig)\n",
    "#     fig.update_layout(title=f\"Raag {raag}\", xaxis_title=\"powers of 3\", yaxis_title=\"powers of 5\")\n",
    "#     # set major ticks\n",
    "#     fig.update_xaxes(tickvals=np.arange(-4, 5))\n",
    "#     fig.update_yaxes(tickvals=np.arange(-2, 3))\n",
    "#     # fig.update_xaxes(tickvals=np.arange(-2, 3), ticktext=[f\"$3^{ii}$\" for ii in np.arange(-2, 3)])\n",
    "#     fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mogra.tgnn import swarwise_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = len(tn.node_coordinates)\n",
    "input_dim = 1  # Feature dimension\n",
    "hidden_dim = 16  # Hidden layer size\n",
    "num_classes = 12  # Number of equivalence classes\n",
    "num_time_steps = 25  # Number of time steps\n",
    "batch_size = 2  # Number of samples in each batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjac = torch.tensor(adjac, dtype=torch.long)\n",
    "equiv = torch.tensor(equiv, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an array from seqs\n",
    "min_length = min([len(ii) for ii in seqs[\"Bhoop\"] + seqs[\"Deshkar\"]])\n",
    "xx = np.array([ii[:min_length] for raag, values in seqs.items() for ii in values])\n",
    "\n",
    "# xx is currently num_samples x sample_length and contains node indices, make it num_samples x num_nodes x sample_length x input_dim with one-hot node encoding\n",
    "xseq = np.zeros((xx.shape[0], num_nodes, xx.shape[1], input_dim))\n",
    "for i in range(xx.shape[0]):\n",
    "    for j in range(xx.shape[1]):\n",
    "        tone_options, _ = tn.get_swar_options(Swar(xx[i, j]%12).name)\n",
    "        for tone_option in tone_options:\n",
    "            xseq[i, tn.node_coordinates.index(tone_option), j, 0] = 1\n",
    "xseq = torch.tensor(xseq, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_indices = lambda nodes: [tn.node_coordinates.index(ii) for ii in nodes]\n",
    "def tn_indices(nodes):\n",
    "    tni = np.zeros(len(tn.node_coordinates), dtype=int)\n",
    "    for ii in [tn.node_coordinates.index(ii) for ii in nodes]:\n",
    "        tni[ii] = 1\n",
    "    return tni\n",
    "yy = np.array([tn_indices(raag_gt_nodes[raag]) for raag, values in seqs.items() for ii in values])\n",
    "\n",
    "# we want to stratify yy labels into 12 classes, with each equivalence class having one (or no) labels\n",
    "yt = torch.tensor(yy, dtype=torch.long)\n",
    "yraag = torch.tensor(np.zeros((yt.shape[0], 12)), dtype=torch.long)\n",
    "for ii, mask in enumerate(equiv.T):\n",
    "    for jj in range(yt.shape[0]):\n",
    "        yraag[jj, ii] = (yt[jj, :] * mask).argmax() if sum(yt[jj, :] * mask) > 0 else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xseq.shape, yraag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DataLoader:\n",
    "# # we have num_samples of length num_nodes x sample_length x input_dim\n",
    "# # we want to break down into num_time_steps from sample_length, and return in batches of batch_size\n",
    "# # so we want to return \"x\"s of batch_size x num_nodes x num_time_steps x input_dim and \"y\"s of batch_size x num_classes\n",
    "\n",
    "# class SeqDataset(Dataset):\n",
    "#     def __init__(self, xseq, yraag, num_time_steps):\n",
    "#         self.xseq = xseq\n",
    "#         self.yraag = yraag\n",
    "#         self.num_time_steps = num_time_steps\n",
    "#         self.seqs_per_sample = xseq.shape[2] // num_time_steps\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.xseq.shape[0] * self.seqs_per_sample\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         sample_idx = idx // self.seqs_per_sample\n",
    "#         insample_idx = idx % self.seqs_per_sample\n",
    "#         x = self.xseq[sample_idx, :, insample_idx*self.num_time_steps:(insample_idx+1)*self.num_time_steps, :]\n",
    "#         y = self.yraag[sample_idx]\n",
    "#         return x, y\n",
    "\n",
    "# dataset = SeqDataset(xseq, yraag, num_time_steps)\n",
    "# # split into train and val\n",
    "# train_size = int(0.8 * len(dataset))\n",
    "# val_size = len(dataset) - train_size\n",
    "# train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully featurize...\n",
    "\n",
    "We only need `equiv` to get `yraag` (don't we?). We use `adjac` in the graph, but it doesn't contain the full information of the network -- namely, the type of edges (x3, x5, /3, /5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adjac.shape, equiv.shape)\n",
    "print(len(tn.node_coordinates))\n",
    "print(xseq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yraag[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one time step\n",
    "x = xseq[0, :, 0, 0]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(tn.node_coordinates)[np.where(x>0)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following features need to be associated with this sample:<br>\n",
    "- a variable length list of \"options\" (lol -- is this even the right approach?)<br>\n",
    "\n",
    "Each \"option\" has the following features:<br>\n",
    "- a 3-coordinate\n",
    "- a 5-coordinate\n",
    "- a cyclic frequency value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cyclic Frequency Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(tn.node_frequencies)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(sorted(tn.node_frequencies), marker=\"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_ratio(ratio):\n",
    "    # Extract the decimal part of the frequencies\n",
    "    decimal_part = ratio % 1\n",
    "\n",
    "    # Convert the decimal parts to angles (in radians)\n",
    "    angle = decimal_part * 2 * np.pi\n",
    "\n",
    "    # Compute the sine and cosine of the angles\n",
    "    sin_feature = np.sin(angle)\n",
    "    cos_feature = np.cos(angle)\n",
    "    cyclic_feature = (sin_feature, cos_feature)\n",
    "    \n",
    "    return cyclic_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = np.array([featurize_ratio(ii) for ii in tn.node_frequencies])\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(node_features[:,0], node_features[:,1], marker=\"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, instead of the labels being for the whole sequence, get them to be per time step..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RecurrentGCN(torch.nn.Module):\n",
    "#     def __init__(self, node_features, hidden_dim):\n",
    "#         super(RecurrentGCN, self).__init__()\n",
    "        \n",
    "#         self.hidden_dim = hidden_dim\n",
    "        \n",
    "#         self.recurrent_forward = GConvGRU(node_features, hidden_dim, K=2)\n",
    "#         self.recurrent_backward = GConvGRU(node_features, hidden_dim, K=2)\n",
    "        \n",
    "#         self.linear = torch.nn.Linear(2 * hidden_dim, 1)\n",
    "    \n",
    "#     def forward(self, x, edge_index, edge_weight=None):\n",
    "#         # x shape: [batch_size, num_nodes, num_time_steps, num_features]\n",
    "#         batch_size, num_nodes, num_time_steps, _ = x.size()\n",
    "        \n",
    "#         # Initialize hidden states for both directions\n",
    "#         h_forward = torch.zeros(batch_size, num_nodes, self.hidden_dim, device=x.device)\n",
    "#         h_backward = torch.zeros(batch_size, num_nodes, self.hidden_dim, device=x.device)\n",
    "        \n",
    "#         # Forward pass through time (0 to T)\n",
    "#         for t in range(num_time_steps):\n",
    "#             x_t = x[:, :, t, :]  # Node features at time step t\n",
    "#             h_forward = self.recurrent_forward(x_t, edge_index, h_forward, edge_weight)\n",
    "        \n",
    "#         # Backward pass through time (T to 0)\n",
    "#         for t in reversed(range(num_time_steps)):\n",
    "#             x_t = x[:, :, t, :]  # Node features at time step t\n",
    "#             h_backward = self.recurrent_backward(x_t, edge_index, h_backward, edge_weight)\n",
    "        \n",
    "#         # Concatenate hidden states from both directions\n",
    "#         h_concat = torch.cat([h_forward, h_backward], dim=-1)  # Shape: [batch_size, num_nodes, 2 * hidden_dim]\n",
    "        \n",
    "#         # Apply linear layer to each node's concatenated hidden state\n",
    "#         h_concat = F.relu(h_concat)\n",
    "#         out = self.linear(h_concat)  # Shape: [batch_size, num_nodes, 1]\n",
    "        \n",
    "#         return out.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the model\n",
    "# model = RecurrentGCN(input_dim, hidden_dim)\n",
    "# # model = TemporalGNN(input_dim, hidden_dim, num_classes, num_time_steps)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1 Step of Training Loop\n",
    "# for x, y in train_dataloader:\n",
    "#     break\n",
    "\n",
    "# optimizer.zero_grad()\n",
    "# out = model(x, adjac, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train + Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "# optimizer.zero_grad()\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    train_loss = 0\n",
    "    for x, y in train_dataloader:\n",
    "        if x.shape[0] != batch_size:\n",
    "            continue\n",
    "        try:\n",
    "            out = model(x, adjac, equiv)\n",
    "        except:\n",
    "            continue\n",
    "        loss = swarwise_loss(out, y, batch_size)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    # print(\"train loss: \", train_loss)\n",
    "    train_losses.append(train_loss/len(train_dataloader))\n",
    "        \n",
    "    val_loss = 0\n",
    "    for x, y in val_dataloader:\n",
    "        if x.shape[0] != batch_size:\n",
    "            continue\n",
    "        try:\n",
    "            out = model(x, adjac, equiv)\n",
    "        except:\n",
    "            continue\n",
    "        loss = swarwise_loss(out, y, batch_size)\n",
    "        val_loss += loss.item()\n",
    "    # print(\"eval loss: \", val_loss)\n",
    "    val_losses.append(val_loss/len(val_dataloader))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(out_scores, threshold):\n",
    "    bs = out_scores.shape[0]\n",
    "    out_cs = out_scores.view(bs*12, -1)\n",
    "    out_cs_argmax = out_cs.argmax(dim=1)\n",
    "    out_cs_max = out_cs.max(dim=1)\n",
    "    for ii, score in enumerate(out_cs_max.values):\n",
    "        if score < threshold:\n",
    "            out_cs_argmax[ii] = -1\n",
    "    out_preds = out_cs_argmax.view(bs, 12)\n",
    "    return out_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "preds = []\n",
    "for x, y in val_dataloader:\n",
    "    out = model(x, adjac, equiv)\n",
    "    preds.extend(get_preds(out, 0.5).flatten().detach().numpy())\n",
    "    labels.extend(y.flatten().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(labels, preds, labels=np.arange(-1, 45, 2))\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', vmax=15, xticklabels=False, yticklabels=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icm-shruti-analysis-XL3d-GDY-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
