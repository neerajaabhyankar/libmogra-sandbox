{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disclaimer: The copyright of data from www.tanarang.com belongs to Tanarang.\n",
    "This is being used purely for academic, non-commercial purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import dill\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT_DIR = os.path.dirname(os.path.abspath(\"\"))\n",
    "sys.path.append(SCRIPT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mogra\n",
    "from conversion_utils import TanarangParsedRaag\n",
    "from mogra.datatypes import SSwar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Srape List of Raags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_url = \"https://www.tanarang.com/english/raagIndex_eng.htm\"\n",
    "resp = requests.get(index_url, headers={\"User-Agent\": ua})\n",
    "if resp.status_code == 200:\n",
    "    index_soup = BeautifulSoup(resp.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the first table\n",
    "table = index_soup.find(\"table\")\n",
    "\n",
    "\n",
    "# Initialize a list of tuples\n",
    "raag_names = []\n",
    "refs = []\n",
    "\n",
    "# Find all rows within the table and append lists of (name, link)\n",
    "rows = table.find_all('tr')\n",
    "for row in rows:\n",
    "    cols = [td.find('a') for td in row.find_all('td')]\n",
    "    names_links = [(a_tag.text.strip(), a_tag.get('href')) for a_tag in cols]\n",
    "    for nn, ll in names_links:\n",
    "        raag_names.append(nn)\n",
    "        refs.append(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"raaglist.csv\", \"w\") as fp:\n",
    "    wr = csv.writer(fp, quoting=csv.QUOTE_ALL)\n",
    "    for name, ref in zip(raag_names, refs):\n",
    "        wr.writerow([name, ref])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Srape List of Raags [Read Copy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raag_names = []\n",
    "refs = []\n",
    "with open(\"raaglist.csv\", \"r\") as fp:\n",
    "    wr = csv.reader(fp, delimiter=\",\")\n",
    "    for line in wr:\n",
    "        raag_names.append(line[0])\n",
    "        refs.append(line[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Raag Infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"bhoop_soup.html\", \"w\", encoding=\"utf-8\") as fp:\n",
    "#     fp.write(str(soup))\n",
    "# with open(\"bhoop_soup.html\", \"r\") as fp:\n",
    "#     bhoop_soup = BeautifulSoup(fp.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infotable_from_soup(raag_soup) -> pd.DataFrame:\n",
    "    # Find the first table\n",
    "    table = raag_soup.find(\"table\")\n",
    "\n",
    "    # Find all rows within the table\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    # Initialize a list to store row data\n",
    "    data = []\n",
    "    headers = [\"info_type\", \"info\"]\n",
    "\n",
    "    # Loop over the rows (excluding the header row)\n",
    "    for row in rows:\n",
    "        cols = row.find_all(['td', 'th'])  # This handles both 'td' and 'th' if 'th' is used within the table body\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "        data.append(cols)  # Add the data\n",
    "\n",
    "    # Convert list of row data into a pandas DataFrame\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, ref in zip(raag_names, refs):\n",
    "    url = f\"https://www.tanarang.com/english/{ref}\"\n",
    "    resp = requests.get(url, headers={\"User-Agent\": ua})\n",
    "    if resp.status_code == 200:\n",
    "        raag_soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    df = infotable_from_soup(raag_soup)\n",
    "    df.to_pickle(f\"infotables/{name}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Raag Info [Read Copy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in raag_names:\n",
    "    df = pd.read_pickle(f\"infotables/{name}.pkl\")\n",
    "    print(name)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deconstruct Info Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"raags_temp.pkl\", \"ab\") as fp:\n",
    "    for name in sorted(raag_names):\n",
    "        df = pd.read_pickle(f\"infotables/{name}.pkl\")\n",
    "        try:\n",
    "            parsed_raag = TanarangParsedRaag(df, name, verbose=False)\n",
    "        except:\n",
    "            print(\"PROBLEM at\", name)\n",
    "            break\n",
    "    \n",
    "        dill.dump(parsed_raag, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If something goes wrong, manually edit the df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[5][1] = \"R P N S'- S' P R\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save and Reload\n",
    "# df.to_pickle(f\"infotables/{name}.pkl\")\n",
    "# df = pd.read_pickle(f\"infotables/{name}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Get alt names + alt spellings + devanagari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: some additions\n",
    "# Abhogi\n",
    "# Amritavarshini\n",
    "# Husseini Kanada\n",
    "# Din Ki Puriya\n",
    "# Marukauns\n",
    "# Shuddha Baradi\n",
    "# Mangal Bhairav\n",
    "# Shobhawari\n",
    "# Sundarkali\n",
    "# Tilang Bahar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "raag_db = {}\n",
    "with open(\"raags_temp.pkl\", \"rb\") as fp:\n",
    "    for name in sorted(raag_names):\n",
    "        raag_db[name] = dill.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "del raag_db[\"Shobhawari\"]\n",
    "del raag_db[\"Suha Sughrai\"]\n",
    "del raag_db[\"Sundarkali\"]\n",
    "del raag_db[\"Tilang Bahar\"]\n",
    "\n",
    "raag_db[\"Basant\"].vaadi = SSwar(\"`\", \"S\")\n",
    "raag_db[\"Sundarkauns\"].vaadi = SSwar(\"\", \"m\")\n",
    "raag_db[\"Sundarkauns\"].samvaadi = SSwar(\"\", \"S\")\n",
    "raag_db[\"Sundarkauns\"].prahar = \"night 2nd\"\n",
    "raag_db[\"Sundarkauns\"].thaat = \"Not Defined\"\n",
    "raag_db[\"Yaman\"].aaroha = TanarangParsedRaag.string_to_swars(\",N R G M D N S'\")\n",
    "raag_db[\"Yaman\"].avaroha = TanarangParsedRaag.string_to_swars(\"S' N D P M G R S ,N R S\")\n",
    "raag_db[\"Yaman\"].vaadi = SSwar(\"\", \"G\")\n",
    "raag_db[\"Yaman\"].samvaadi = SSwar(\"\", \"N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"raags_new.pkl\", \"wb\") as fp:\n",
    "    for rd in raag_db.values():\n",
    "        rd.df = None\n",
    "        rd.verbose = None\n",
    "        dill.dump(rd, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"raags_new.pkl\", \"rb\") as fp:\n",
    "    raag_db = {}\n",
    "    while True:\n",
    "        try:\n",
    "            rd = dill.load(fp)\n",
    "            raag_db[rd.name] = rd\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raag_db[\"Yaman\"].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the db to a portable pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_str(ss):\n",
    "    try:\n",
    "        rr = ss.__str__()\n",
    "    except:\n",
    "        rr = str(ss)\n",
    "    assert type(rr) == str\n",
    "    return rr\n",
    "\n",
    "raag_dict_s = {}\n",
    "for name, rd in raag_db.items():\n",
    "    rd_dict = rd.__dict__\n",
    "    rd_dict[\"aaroha\"] = [make_str(ss) for ss in rd_dict[\"aaroha\"]]\n",
    "    rd_dict[\"avaroha\"] = [make_str(ss) for ss in rd_dict[\"avaroha\"]]\n",
    "    rd_dict[\"mukhyanga\"] = [[make_str(ss) for ss in mm] for mm in rd_dict[\"mukhyanga\"]]\n",
    "    rd_dict[\"aarohi_nyas\"] = [make_str(ss) for ss in rd_dict[\"aarohi_nyas\"]]\n",
    "    rd_dict[\"avarohi_nyas\"] = [make_str(ss) for ss in rd_dict[\"avarohi_nyas\"]]\n",
    "    rd_dict[\"vaadi\"] = make_str(rd_dict[\"vaadi\"])\n",
    "    rd_dict[\"samvaadi\"] = make_str(rd_dict[\"samvaadi\"])\n",
    "    raag_dict_s[name] = rd_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raag_dict_s[\"Yaman\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(raag_dict_s, open(\"raag_dicts_2.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(raag_dict_s[\"Yaman\"][\"avaroha\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icm-shruti-analysis-XL3d-GDY-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
