{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03f7c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "from IPython.display import Audio as ipy_audio\n",
    "from quicktranscribe.wave import read_audio_section\n",
    "from quicktranscribe import kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67c5700",
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_file = \"GhodePeSawaar.mp3\"\n",
    "ngtj_file = \"NasatesaGhariTuJevha.wav\"\n",
    "bhoop_file = \"Omkar Dadarkar - Raag Bhoopali.mp3\"\n",
    "malkauns_file = \"Ajoy Chakrabarty - Malkauns.mp3\"\n",
    "rjha_sarang = \"rjha_sarang.mp3\"\n",
    "audios_dir = \"misc-audios/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4135080b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "025dec2b",
   "metadata": {},
   "source": [
    "### quicktranscribe example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d69ff7",
   "metadata": {},
   "source": [
    "sarang 4:15 to 4:58 <br>\n",
    "megh 5:23 to 5:41, 5:55 to 6:25 <br>\n",
    "megh best 7:10 to 8:42 <br>\n",
    "comparison 8:48 to 9:21 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06:45 to 07:00\n",
    "start = 8*60+48\n",
    "end = 9*60+21\n",
    "y_stereo, sr = read_audio_section(audios_dir + rjha_sarang, start, end)\n",
    "y = librosa.to_mono(y_stereo.T)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipy_audio(data=y, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0, _, voiced_probab = librosa.pyin(y, fmin=50, fmax=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3386c7",
   "metadata": {},
   "source": [
    "Find tonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0dba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtonic = 60  # TEMP GUESS\n",
    "\n",
    "kde_sample = kde.extract(y, sr=sr, tonic=gtonic)\n",
    "peaks, _ = kde.prominence_based_peak_finder(kde_sample, prominence=0.005)\n",
    "print(peaks)\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(np.linspace(0, 12, len(kde_sample)), kde_sample, color=\"teal\")\n",
    "plt.plot(np.array(peaks) * 12/len(kde_sample), kde_sample[peaks], \"o\", markersize=\"3\", color=\"orange\")\n",
    "plt.xlabel(\"relative note index\")\n",
    "plt.ylabel(\"normalized duration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdd52f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(peaks) * 12/len(kde_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ec0138",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = 0.05\n",
    "ctonic = librosa.midi_to_hz(librosa.hz_to_midi(gtonic) + sa)\n",
    "print(ctonic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b3fefc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe9d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctonic = 60.17353727216203\n",
    "sarang_R = ctonic*9/8\n",
    "megh_R = ctonic*10/9\n",
    "sarang_n = ctonic*9/10\n",
    "megh_n = ctonic*8/9\n",
    "both_P = ctonic*3/2\n",
    "both_m = ctonic*4/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd49554",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(f0, linewidth=1)\n",
    "plt.rcParams[\"figure.dpi\"] = 500\n",
    "plt.yticks([megh_n, sarang_n, ctonic, megh_R, sarang_R, both_m, both_P])\n",
    "plt.ylim([52,97])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e453ea76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a636820e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43835bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 4*60+15\n",
    "end = 4*60+58\n",
    "y_stereo, sr = read_audio_section(audios_dir + rjha_sarang, start, end)\n",
    "y = librosa.to_mono(y_stereo.T)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0, _, voiced_probab = librosa.pyin(y, fmin=50, fmax=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e2bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtonic = 60  # TEMP GUESS\n",
    "\n",
    "kde_sample = kde.extract(y, sr=sr, tonic=gtonic)\n",
    "peaks, _ = kde.prominence_based_peak_finder(kde_sample, prominence=0.005)\n",
    "# print(peaks)\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(np.linspace(0, 12, len(kde_sample)), kde_sample, color=\"teal\")\n",
    "plt.plot(np.array(peaks) * 12/len(kde_sample), kde_sample[peaks], \"o\", markersize=\"3\", color=\"orange\")\n",
    "plt.xlabel(\"relative note index\")\n",
    "plt.ylabel(\"normalized duration\")\n",
    "print(np.array(peaks) * 12/len(kde_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a52f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = 0.0\n",
    "ctonic = librosa.midi_to_hz(librosa.hz_to_midi(gtonic) + sa)\n",
    "print(ctonic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a2d228",
   "metadata": {},
   "outputs": [],
   "source": [
    "sarang_R = ctonic*9/8\n",
    "megh_R = ctonic*10/9\n",
    "sarang_n = ctonic*9/10\n",
    "megh_n = ctonic*8/9\n",
    "both_P = ctonic*3/2\n",
    "both_m = ctonic*4/3\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(f0, linewidth=1)\n",
    "plt.rcParams[\"figure.dpi\"] = 500\n",
    "plt.yticks([megh_n, sarang_n, ctonic, megh_R, sarang_R, both_m, both_P])\n",
    "plt.ylim([52,97])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83002d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipy_audio(data=y, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4496151b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d3f3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434e6a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 7*60+15\n",
    "end = 7*60+42\n",
    "y_stereo, sr = read_audio_section(audios_dir + rjha_sarang, start, end)\n",
    "y = librosa.to_mono(y_stereo.T)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962ceca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0, _, voiced_probab = librosa.pyin(y, fmin=50, fmax=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d1cd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtonic = 60  # TEMP GUESS\n",
    "\n",
    "kde_sample = kde.extract(y, sr=sr, tonic=gtonic)\n",
    "peaks, _ = kde.prominence_based_peak_finder(kde_sample, prominence=0.005)\n",
    "# print(peaks)\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(np.linspace(0, 12, len(kde_sample)), kde_sample, color=\"teal\")\n",
    "plt.plot(np.array(peaks) * 12/len(kde_sample), kde_sample[peaks], \"o\", markersize=\"3\", color=\"orange\")\n",
    "plt.xlabel(\"relative note index\")\n",
    "plt.ylabel(\"normalized duration\")\n",
    "print(np.array(peaks) * 12/len(kde_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21e5bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = 0\n",
    "ctonic = librosa.midi_to_hz(librosa.hz_to_midi(gtonic) + sa)\n",
    "print(ctonic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aaadb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sarang_R = ctonic*9/8\n",
    "megh_R = ctonic*10/9\n",
    "sarang_n = ctonic*9/10\n",
    "megh_n = ctonic*8/9\n",
    "both_P = ctonic*3/2\n",
    "both_m = ctonic*4/3\n",
    "sarang_nh = 2*ctonic*9/10\n",
    "megh_nh = 2*ctonic*8/9\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(f0, linewidth=1)\n",
    "plt.rcParams[\"figure.dpi\"] = 500\n",
    "plt.yticks([megh_n, sarang_n, ctonic, megh_R, sarang_R, both_m, both_P, megh_nh, sarang_nh, ctonic*2])\n",
    "plt.ylim([47,137])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8089abe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipy_audio(data=y, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4469467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d3083a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c856191d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d673d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cb1fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32989b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librosa spectral features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 6\n",
    "end = 16\n",
    "y_stereo, sr = read_audio_section(malkauns_file, start, end)\n",
    "y = librosa.to_mono(y_stereo.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipy_audio(data=y, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.abs(librosa.stft(y, n_fft=4096))**2\n",
    "img = librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max), y_axis='log', x_axis='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.abs(librosa.stft(y, n_fft=4096))**2\n",
    "chroma = librosa.feature.chroma_stft(S=S, sr=sr)\n",
    "img = librosa.display.specshow(chroma, y_axis='chroma_h', x_axis='time', thaat='bhairavi', Sa=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CQT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.abs(librosa.cqt(y, sr=sr))\n",
    "img = librosa.display.specshow(librosa.amplitude_to_db(C, ref=np.max), sr=sr, x_axis='time', y_axis='cqt_note')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_cq = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "img = librosa.display.specshow(chroma_cq, y_axis='chroma_h', x_axis='time', thaat='bhairavi', Sa=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VQT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.abs(librosa.vqt(y, sr=sr, bins_per_octave=36, fmin=librosa.note_to_hz('C2')))\n",
    "img = librosa.display.specshow(librosa.amplitude_to_db(V, ref=np.max), sr=sr, x_axis='time', y_axis='cqt_note')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_vq = librosa.vqt(y, sr=sr, bins_per_octave=36, fmin=librosa.note_to_hz('C2'))\n",
    "img = librosa.display.specshow(chroma_vq, y_axis='vqt_fjs', x_axis='time', thaat='bhairavi', Sa=1, intervals='ji5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Zero crossing:\n",
    "The  higher this is, the less reliable our computed frequency is?? Why??\n",
    "\"\"\"\n",
    "zc = librosa.feature.zero_crossing_rate(y)[0]\n",
    "plt.plot(zc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85623385",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" RMS:\n",
    "Correlates with the energy in the signal over time. The RMS is probably over the f domain, so a sharp f --> a higher RMS??\n",
    "\"\"\"\n",
    "rms = librosa.feature.rms(y=y)[0]\n",
    "plt.plot(rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc = librosa.feature.mfcc(y=y, sr=sr, dct_type=2)\n",
    "plt.figure(figsize=(10,5))\n",
    "# ax = plt.gca()\n",
    "img = librosa.display.specshow(mfcc, x_axis='time')\n",
    "# ax.matshow(mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdbea592",
   "metadata": {},
   "source": [
    "### speech_recongition example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7327e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()\n",
    "\n",
    "# Reading Audio File and storing in a variable\n",
    "with sr.AudioFile(ngtj_file) as source:\n",
    "    audio_text = r.listen(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92afb8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = r.recognize_google(audio_text, language=\"mr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2400f48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81db236",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icm-shruti-analysis-XL3d-GDY-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
